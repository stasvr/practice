{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 14, 13],\n",
       "       [ 2,  4, 10]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sequence(lower, upper, n, q):\n",
    "    seq = np.random.randint(lower, upper, size=(q, np.random.choice(n)))\n",
    "    return seq\n",
    "generate_sequence(1, 15, [3,6,9], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varshavskiisd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 3\n",
    "max_len = 10\n",
    "loss_track = list()\n",
    "score = list()\n",
    "train_size = None\n",
    "test_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqToSeq:\n",
    "    vocab_size = 15\n",
    "    \n",
    "    def __init__(self, hidden_units, optimizer=tf.train.AdamOptimizer()):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Placeholders and variables used in graph\n",
    "        self.in_encoder = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "        self.in_decoder = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "        self.out_decoder = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "        \n",
    "        input_embedding_size = 20\n",
    "        embeddings = tf.Variable(tf.random_uniform([self.vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "        encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, self.in_encoder)\n",
    "        decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, self.in_decoder)\n",
    "        \n",
    "        # encoder\n",
    "        tmp1 = [\n",
    "            hidden_units[0],\n",
    "            encoder_inputs_embedded\n",
    "        ]\n",
    "        encoder_outputs, encoder_final_state = self.encoder(tmp1)\n",
    "        \n",
    "        # decoder\n",
    "        tmp2 = [\n",
    "            hidden_units[1],\n",
    "            decoder_inputs_embedded,\n",
    "            encoder_final_state\n",
    "        ]\n",
    "        decoder_outputs, decoder_final_state = self.decoder(tmp2)\n",
    "        \n",
    "        decoder_logits = tf.contrib.layers.linear(decoder_outputs, self.vocab_size)\n",
    "        self.decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "        \n",
    "        # Initialisation of loss funstion and optimisation method with constraits for weights changing\n",
    "        self._loss = self.cost([self.out_decoder, decoder_logits])\n",
    "        self._optimizer = optimizer.minimize(self._loss)\n",
    "        \n",
    "        \n",
    "    def encoder(self, inner):\n",
    "        encoder_cell = tf.contrib.rnn.LSTMCell(inner[0])\n",
    "        encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(encoder_cell, inner[1],\n",
    "                                                                 dtype=tf.float32,\n",
    "                                                                 time_major=True)\n",
    "        \n",
    "        return encoder_outputs, encoder_final_state\n",
    "\n",
    "    def decoder(self, inner):\n",
    "        decoder_cell = tf.contrib.rnn.LSTMCell(inner[0])\n",
    "        decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(decoder_cell, inner[1],\n",
    "                                                                 initial_state=inner[2],\n",
    "                                                                 dtype=tf.float32, time_major=True,\n",
    "                                                                 scope=\"plain_decoder\")\n",
    "        return decoder_outputs, decoder_final_state\n",
    "    \n",
    "    def cost(self, inner):\n",
    "        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(inner[0], depth=self.vocab_size, dtype=tf.float32),\n",
    "            logits=inner[1])\n",
    "        \n",
    "        loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "        return loss\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self._loss\n",
    "    \n",
    "    @property\n",
    "    def optimze(self):\n",
    "        return self._optimizer\n",
    "    \n",
    "class Process:\n",
    "    \n",
    "    def __init__(self, data, params):\n",
    "        self._epochs, self._batch_size = params['epochs'], params['batch_size']\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        self._sess = tf.Session()\n",
    "        self._sess.run(init)\n",
    "\n",
    "        self._data, last, self._iterations = list(), 0, int(data.shape[0] / self._batch_size)\n",
    "        for i in range(self._iterations-1):\n",
    "            if i != 0:\n",
    "                self._data.append(data[last:i * self._batch_size])\n",
    "                last = i * self._batch_size\n",
    "    \n",
    "    def run(self, n, graph):\n",
    "        PAD, EOS = 0, 1\n",
    "        for e in range(self._epochs):\n",
    "            for i in range(self._iterations-1):\n",
    "                batch = self._data[np.random.randint(len(self._data)-1)]\n",
    "                feed = {\n",
    "                    graph.in_encoder : np.array([[PAD] + [j for j in i] for i in batch]),\n",
    "                    graph.in_decoder : np.array([[EOS] + [j for j in i] for i in batch]),\n",
    "                    graph.out_decoder : np.array([[j for j in i] + [EOS] for i in batch])\n",
    "                }\n",
    "                _,l = self._sess.run([graph.optimze, graph.loss], feed_dict=feed)\n",
    "            if e % n == 0:\n",
    "                print('Epoch:', e, 'Loss:', l)\n",
    "                \n",
    "        return self._sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 14,  7,  2],\n",
       "       [11,  4,  9, 13]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_sequence(2, 15, [3,4], 100)\n",
    "base = len(data[0])\n",
    "for idx, i in enumerate(data):\n",
    "    r = base - np.random.randint(2)\n",
    "    data[idx] = [PAD] * (base-r) + [j for jdx, j in enumerate(i) if jdx < r]\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.6635756\n",
      "Epoch: 100 Loss: 1.6237664\n",
      "Epoch: 200 Loss: 1.1696355\n",
      "Epoch: 300 Loss: 0.7944676\n",
      "Epoch: 400 Loss: 0.7023334\n",
      "Epoch: 500 Loss: 0.53384244\n",
      "Epoch: 600 Loss: 0.54649156\n",
      "Epoch: 700 Loss: 0.42520565\n",
      "Epoch: 800 Loss: 0.39173388\n",
      "Epoch: 900 Loss: 0.34690636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fbde2c610b8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "seq2seq = SeqToSeq(hidden_units=[10, 10])\n",
    "process = Process(data, { 'batch_size' : 20, 'epochs' : 1000})\n",
    "process.run(100, seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd, last, iterations = list(), 0, int(data.shape[0] / 20)\n",
    "for i in range(iterations):\n",
    "    if i != 0:\n",
    "        asd.append(data[last:i * 20])\n",
    "        last = i * 2\n",
    "asd[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Loss : 2.752517\n",
      "  sample 1:\n",
      "    input     > [ 0  0  7  8 10]\n",
      "    predicted > [13  0  4  3  3]\n",
      "  sample 2:\n",
      "    input     > [ 0 13  5 13 13]\n",
      "    predicted > [13  9  4  1  9]\n",
      "  sample 3:\n",
      "    input     > [ 0  8 13  4  9]\n",
      "    predicted > [13  0  4  5  9]\n",
      "  sample 4:\n",
      "    input     > [0 0 5 3 9]\n",
      "    predicted > [13  0  4  1  9]\n",
      "Epoch : 500  Loss : 1.3065455\n",
      "  sample 1:\n",
      "    input     > [ 0  0  7  8 10]\n",
      "    predicted > [ 0  5  8 13  3]\n",
      "  sample 2:\n",
      "    input     > [ 0 13  5 13 13]\n",
      "    predicted > [ 0  5 13 13  3]\n",
      "  sample 3:\n",
      "    input     > [ 0  8 13  4  9]\n",
      "    predicted > [ 0 13  4  9  3]\n",
      "  sample 4:\n",
      "    input     > [0 0 5 3 9]\n",
      "    predicted > [0 5 3 9 3]\n",
      "Epoch : 1000  Loss : 1.00697\n",
      "  sample 1:\n",
      "    input     > [ 0  0  7  8 10]\n",
      "    predicted > [ 0  7  8 10  3]\n",
      "  sample 2:\n",
      "    input     > [ 0 13  5 13 13]\n",
      "    predicted > [13  5 13 13  3]\n",
      "  sample 3:\n",
      "    input     > [ 0  8 13  4  9]\n",
      "    predicted > [ 8 13  4  9  3]\n",
      "  sample 4:\n",
      "    input     > [0 0 5 3 9]\n",
      "    predicted > [0 5 3 9 3]\n"
     ]
    }
   ],
   "source": [
    "seq2seq = SeqToSeq(hidden_units=[10, 10])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for epoch in range(1001):\n",
    "    tmp = iter(asd)\n",
    "    for i in range(iterations-1):\n",
    "        batch = next(tmp)#asd[np.random.randint(5-1)]\n",
    "        feed = {\n",
    "            seq2seq.in_encoder : np.array([[PAD] + [j for j in i] for i in batch]),\n",
    "            seq2seq.in_decoder : np.array([[EOS] + [j for j in i] for i in batch]),\n",
    "            seq2seq.out_decoder : np.array([[j for j in i] + [EOS] for i in batch])\n",
    "        }\n",
    "        _,l = sess.run([seq2seq.optimze, seq2seq.loss], feed_dict=feed)\n",
    "    if epoch % 500 == 0:\n",
    "        print('Epoch : ' + str(epoch),' Loss : ' + str(l))\n",
    "        feed = {\n",
    "                seq2seq.in_encoder : np.array([[PAD] +[j for j in i] for i in asd[0]]),\n",
    "                seq2seq.in_decoder : np.array([[EOS] + [j for j in i] for i in asd[0]])\n",
    "        }\n",
    "        pred = sess.run(seq2seq.decoder_prediction, feed_dict=feed)\n",
    "        for k, (inp, pred) in enumerate(zip(feed[seq2seq.in_encoder], pred)):\n",
    "            print('  sample {}:'.format(k + 1))\n",
    "            print('    input     > {}'.format(inp))\n",
    "            print('    predicted > {}'.format(pred))\n",
    "            if k > 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
